{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49ab9aa5",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3351717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import deque, defaultdict\n",
    "import time\n",
    "from typing import List, Dict, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e680b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "actors = {}\n",
    "movies = {}\n",
    "actor_movies = defaultdict(list)  # actor_id -> [movie_ids]\n",
    "movie_actors = defaultdict(list)  # movie_id -> [actor_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "499a865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(people_csv='Dataset_FinalExam\\Q1_dataset\\small\\people.csv', movies_csv='Dataset_FinalExam\\Q1_dataset\\small\\movies.csv', stars_csv='Dataset_FinalExam\\Q1_dataset\\small\\stars.csv'):\n",
    "    \"\"\"\n",
    "    Load all CSV data into global variables\n",
    "    Just run this once at the beginning!\n",
    "    \"\"\"\n",
    "    global actors, movies, actor_movies, movie_actors\n",
    "    \n",
    "    try:\n",
    "        print(\"üîÑ Loading data...\")\n",
    "        \n",
    "        # Load people data\n",
    "        people_df = pd.read_csv(people_csv)\n",
    "        for _, row in people_df.iterrows():\n",
    "            actors[row['id']] = {\n",
    "                'id': row['id'],\n",
    "                'name': row['name'],\n",
    "                'birth': row['birth']\n",
    "            }\n",
    "        \n",
    "        # Load movies data\n",
    "        movies_df = pd.read_csv(movies_csv)\n",
    "        for _, row in movies_df.iterrows():\n",
    "            movies[row['id']] = {\n",
    "                'id': row['id'],\n",
    "                'title': row['title'],\n",
    "                'year': row['year']\n",
    "            }\n",
    "        \n",
    "        # Load stars data and build connections\n",
    "        stars_df = pd.read_csv(stars_csv)\n",
    "        for _, row in stars_df.iterrows():\n",
    "            person_id = row['person_id']\n",
    "            movie_id = row['movie_id']\n",
    "            \n",
    "            actor_movies[person_id].append(movie_id)\n",
    "            movie_actors[movie_id].append(person_id)\n",
    "        \n",
    "        print(f\"‚úÖ Data loaded successfully!\")\n",
    "        print(f\"   üìä Actors: {len(actors)}\")\n",
    "        print(f\"   üé¨ Movies: {len(movies)}\")\n",
    "        print(f\"   üîó Connections: {len(stars_df)}\")\n",
    "        \n",
    "        # Some cool stats\n",
    "        total_connections = sum(len(movies_list) for movies_list in actor_movies.values())\n",
    "        avg_movies = total_connections / len(actors) if actors else 0\n",
    "        print(f\"   üìà Average movies per actor: {avg_movies:.1f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c07fd26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_shortest_path(start_actor_id, end_actor_id):\n",
    "    \"\"\"\n",
    "    BFS Algorithm to find shortest connection between two actors\n",
    "    Returns: [actor1, movie1, actor2, movie2, ..., target_actor] or None\n",
    "    \"\"\"\n",
    "    if start_actor_id == end_actor_id:\n",
    "        return [start_actor_id]\n",
    "    \n",
    "    if start_actor_id not in actors or end_actor_id not in actors:\n",
    "        return None\n",
    "    \n",
    "    # BFS setup\n",
    "    queue = deque([[start_actor_id]])\n",
    "    visited = {start_actor_id}\n",
    "    \n",
    "    while queue:\n",
    "        path = queue.popleft()\n",
    "        current_actor = path[-1]\n",
    "        \n",
    "        # Get all movies this actor appeared in\n",
    "        for movie_id in actor_movies[current_actor]:\n",
    "            # Get all co-actors in this movie\n",
    "            for co_actor_id in movie_actors[movie_id]:\n",
    "                if co_actor_id == current_actor:\n",
    "                    continue\n",
    "                \n",
    "                if co_actor_id == end_actor_id:\n",
    "                    # Found target! Return complete path\n",
    "                    return path + [movie_id, co_actor_id]\n",
    "                \n",
    "                if co_actor_id not in visited:\n",
    "                    visited.add(co_actor_id)\n",
    "                    queue.append(path + [movie_id, co_actor_id])\n",
    "    \n",
    "    return None  # No connection found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70208428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_actors(query):\n",
    "    \"\"\"Search for actors by name (partial match, case-insensitive)\"\"\"\n",
    "    query = query.lower()\n",
    "    matches = []\n",
    "    \n",
    "    for actor_id, actor_info in actors.items():\n",
    "        if query in actor_info['name'].lower():\n",
    "            matches.append(actor_info)\n",
    "    \n",
    "    return sorted(matches, key=lambda x: x['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39a9e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_path(path, show_timing=True):\n",
    "    \"\"\"Display the connection path in a nice format\"\"\"\n",
    "    if not path:\n",
    "        print(\"‚ùå No connection found!\")\n",
    "        return\n",
    "    \n",
    "    if len(path) == 1:\n",
    "        actor = actors[path[0]]\n",
    "        print(f\"üé≠ Same actor: {actor['name']}\")\n",
    "        return\n",
    "    \n",
    "    # Calculate degrees of separation\n",
    "    degrees = len(path) // 2\n",
    "    \n",
    "    print(f\"\\nüéØ CONNECTION FOUND!\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"üéØ Degrees of Separation: {degrees}\")\n",
    "    print(f\"üìè Path Length: {len(path)} steps\")\n",
    "    \n",
    "    print(f\"\\nüõ§Ô∏è  CONNECTION PATH:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    for i in range(0, len(path), 2):\n",
    "        actor_id = path[i]\n",
    "        actor = actors[actor_id]\n",
    "        \n",
    "        if i == 0:\n",
    "            print(f\"üé≠ {actor['name']} ({actor['birth']})\")\n",
    "        else:\n",
    "            print(f\"    ‚¨áÔ∏è\")\n",
    "            print(f\"üé≠ {actor['name']} ({actor['birth']})\")\n",
    "        \n",
    "        # Add movie info if not the last actor\n",
    "        if i < len(path) - 1:\n",
    "            movie_id = path[i + 1]\n",
    "            movie = movies[movie_id]\n",
    "            print(f\"    üé¨ appeared together in: \\\"{movie['title']}\\\" ({movie['year']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3498b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_connection_interactive():\n",
    "    \"\"\"Interactive function to find connections between actors\"\"\"\n",
    "    print(\"\\nüîç FIND CONNECTION BETWEEN ACTORS\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    # Get first actor\n",
    "    while True:\n",
    "        query1 = input(\"Enter first actor name (or part of it): \").strip()\n",
    "        if not query1:\n",
    "            continue\n",
    "            \n",
    "        matches1 = search_actors(query1)\n",
    "        if not matches1:\n",
    "            print(f\"‚ùå No actors found matching '{query1}'\")\n",
    "            continue\n",
    "        elif len(matches1) == 1:\n",
    "            actor1 = matches1[0]\n",
    "            break\n",
    "        else:\n",
    "            print(f\"\\nüìã Found {len(matches1)} matches:\")\n",
    "            for i, actor in enumerate(matches1, 1):\n",
    "                print(f\"{i}. {actor['name']} ({actor['birth']})\")\n",
    "            \n",
    "            try:\n",
    "                choice = int(input(f\"Select actor (1-{len(matches1)}): \")) - 1\n",
    "                if 0 <= choice < len(matches1):\n",
    "                    actor1 = matches1[choice]\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"‚ùå Invalid choice\")\n",
    "            except ValueError:\n",
    "                print(\"‚ùå Invalid input\")\n",
    "    \n",
    "    # Get second actor\n",
    "    while True:\n",
    "        query2 = input(\"Enter second actor name (or part of it): \").strip()\n",
    "        if not query2:\n",
    "            continue\n",
    "            \n",
    "        matches2 = search_actors(query2)\n",
    "        if not matches2:\n",
    "            print(f\"‚ùå No actors found matching '{query2}'\")\n",
    "            continue\n",
    "        elif len(matches2) == 1:\n",
    "            actor2 = matches2[0]\n",
    "            break\n",
    "        else:\n",
    "            print(f\"\\nüìã Found {len(matches2)} matches:\")\n",
    "            for i, actor in enumerate(matches2, 1):\n",
    "                print(f\"{i}. {actor['name']} ({actor['birth']})\")\n",
    "            \n",
    "            try:\n",
    "                choice = int(input(f\"Select actor (1-{len(matches2)}): \")) - 1\n",
    "                if 0 <= choice < len(matches2):\n",
    "                    actor2 = matches2[choice]\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"‚ùå Invalid choice\")\n",
    "            except ValueError:\n",
    "                print(\"‚ùå Invalid input\")\n",
    "    \n",
    "    if actor1['id'] == actor2['id']:\n",
    "        print(\"‚ùå Please select two different actors!\")\n",
    "        return\n",
    "    \n",
    "    # Find and display connection\n",
    "    print(f\"\\nüîç Searching for connection between {actor1['name']} and {actor2['name']}...\")\n",
    "    start_time = time.time()\n",
    "    path = find_shortest_path(actor1['id'], actor2['id'])\n",
    "    search_time = (time.time() - start_time) * 1000\n",
    "    \n",
    "    display_path(path)\n",
    "    if path:\n",
    "        print(f\"‚ö° Search completed in {search_time:.2f}ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6000c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_actors():\n",
    "    \"\"\"Display all actors in the database\"\"\"\n",
    "    print(f\"\\nüë• ALL ACTORS ({len(actors)} total):\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    sorted_actors = sorted(actors.values(), key=lambda x: x['name'])\n",
    "    for i, actor in enumerate(sorted_actors, 1):\n",
    "        movie_count = len(actor_movies[actor['id']])\n",
    "        print(f\"{i:2d}. {actor['name']} ({actor['birth']}) - {movie_count} movies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "750a5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor_filmography(actor_name):\n",
    "    \"\"\"Get filmography for an actor by name\"\"\"\n",
    "    matches = search_actors(actor_name)\n",
    "    \n",
    "    if not matches:\n",
    "        print(f\"‚ùå No actors found matching '{actor_name}'\")\n",
    "        return\n",
    "    \n",
    "    if len(matches) > 1:\n",
    "        print(f\"üìã Found {len(matches)} matches:\")\n",
    "        for i, actor in enumerate(matches, 1):\n",
    "            print(f\"{i}. {actor['name']} ({actor['birth']})\")\n",
    "        return\n",
    "    \n",
    "    actor = matches[0]\n",
    "    print(f\"\\nüé≠ {actor['name']} - Filmography:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Get movies and sort by year\n",
    "    actor_movie_ids = actor_movies[actor['id']]\n",
    "    filmography = []\n",
    "    \n",
    "    for movie_id in actor_movie_ids:\n",
    "        movie_info = movies[movie_id].copy()\n",
    "        # Add co-stars\n",
    "        co_stars = [actors[aid]['name'] for aid in movie_actors[movie_id] if aid != actor['id']]\n",
    "        movie_info['co_stars'] = co_stars\n",
    "        filmography.append(movie_info)\n",
    "    \n",
    "    filmography.sort(key=lambda x: x['year'])\n",
    "    \n",
    "    for movie in filmography:\n",
    "        co_stars_str = \", \".join(movie['co_stars'][:3])\n",
    "        if len(movie['co_stars']) > 3:\n",
    "            co_stars_str += f\" (+{len(movie['co_stars'])-3} more)\"\n",
    "        \n",
    "        print(f\"üé¨ {movie['title']} ({movie['year']})\")\n",
    "        if co_stars_str:\n",
    "            print(f\"   üë• Co-stars: {co_stars_str}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "862ddae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_connection(actor1_name, actor2_name):\n",
    "    \"\"\"Quick function to find connection between two actors by name\"\"\"\n",
    "    # Find actors\n",
    "    matches1 = search_actors(actor1_name)\n",
    "    matches2 = search_actors(actor2_name)\n",
    "    \n",
    "    if not matches1:\n",
    "        print(f\"‚ùå No actors found matching '{actor1_name}'\")\n",
    "        return\n",
    "    if not matches2:\n",
    "        print(f\"‚ùå No actors found matching '{actor2_name}'\")\n",
    "        return\n",
    "    \n",
    "    # Use first match for each\n",
    "    actor1 = matches1[0]\n",
    "    actor2 = matches2[0]\n",
    "    \n",
    "    print(f\"üîç Finding connection: {actor1['name']} ‚Üî {actor2['name']}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    path = find_shortest_path(actor1['id'], actor2['id'])\n",
    "    search_time = (time.time() - start_time) * 1000\n",
    "    \n",
    "    display_path(path)\n",
    "    if path:\n",
    "        print(f\"‚ö° Search completed in {search_time:.2f}ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9e95c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_actor_connections(actor_name):\n",
    "    \"\"\"Analyze all possible connections for an actor\"\"\"\n",
    "    matches = search_actors(actor_name)\n",
    "    if not matches:\n",
    "        print(f\"‚ùå No actors found matching '{actor_name}'\")\n",
    "        return\n",
    "    \n",
    "    actor = matches[0]\n",
    "    print(f\"\\nüìä CONNECTION ANALYSIS for {actor['name']}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    connections = {}\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Find shortest path to all other actors\n",
    "    for target_id, target_actor in actors.items():\n",
    "        if target_id == actor['id']:\n",
    "            continue\n",
    "        \n",
    "        path = find_shortest_path(actor['id'], target_id)\n",
    "        if path:\n",
    "            degrees = len(path) // 2\n",
    "            if degrees not in connections:\n",
    "                connections[degrees] = []\n",
    "            connections[degrees].append(target_actor['name'])\n",
    "    \n",
    "    analysis_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"‚ö° Analysis completed in {analysis_time:.2f}s\")\n",
    "    print(f\"üîó Connected to {len(sum(connections.values(), []))} actors\")\n",
    "    print(f\"‚ùå No connection to {len(actors) - 1 - len(sum(connections.values(), []))} actors\")\n",
    "    \n",
    "    for degree in sorted(connections.keys()):\n",
    "        print(f\"\\n{degree} degree{'s' if degree > 1 else ''} of separation: {len(connections[degree])} actors\")\n",
    "        if degree <= 2:  # Show details for close connections\n",
    "            for name in sorted(connections[degree])[:10]:  # Show first 10\n",
    "                print(f\"   ‚Ä¢ {name}\")\n",
    "            if len(connections[degree]) > 10:\n",
    "                print(f\"   ... and {len(connections[degree]) - 10} more\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "317b46e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading data...\n",
      "‚úÖ Data loaded successfully!\n",
      "   üìä Actors: 16\n",
      "   üé¨ Movies: 5\n",
      "   üîó Connections: 20\n",
      "   üìà Average movies per actor: 1.2\n",
      "üîç Finding connection: Tom Hanks ‚Üî Tom Cruise\n",
      "\n",
      "üéØ CONNECTION FOUND!\n",
      "==================================================\n",
      "üéØ Degrees of Separation: 2\n",
      "üìè Path Length: 5 steps\n",
      "\n",
      "üõ§Ô∏è  CONNECTION PATH:\n",
      "------------------------------\n",
      "üé≠ Tom Hanks (1956)\n",
      "    üé¨ appeared together in: \"Apollo 13\" (1995)\n",
      "    ‚¨áÔ∏è\n",
      "üé≠ Kevin Bacon (1958)\n",
      "    üé¨ appeared together in: \"A Few Good Men\" (1992)\n",
      "    ‚¨áÔ∏è\n",
      "üé≠ Tom Cruise (1962)\n",
      "‚ö° Search completed in 0.00ms\n"
     ]
    }
   ],
   "source": [
    "load_data()\n",
    "# find_connection_interactive()\n",
    "quick_connection(\"Tom Hanks\", \"Tom Cruise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c51b597",
   "metadata": {},
   "source": [
    "Why BFS is perfect here:\n",
    "1. Finds SHORTEST path guaranteed (explores level by level)\n",
    "2. Unweighted graph - all connections equal\n",
    "3. Fast: O(V + E) time complexity\n",
    "4. Memory efficient with deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36d10a",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a299c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a37daf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=\"Dataset_FinalExam\\\\Q2_dataset\", img_width=32, img_height=32):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Loop through each category folder (assumed to be named 0 to 42)\n",
    "    for label in range(43):  # 0 to 42 inclusive\n",
    "        print(f\"Loading images for label: {label}\")\n",
    "        folder_path = os.path.join(data_dir, str(label))\n",
    "        \n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue  # skip if not a directory\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.ppm'):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                img = cv2.imread(img_path)\n",
    "                \n",
    "                if img is None:\n",
    "                    continue  # skip unreadable files\n",
    "\n",
    "                # Resize image to desired size\n",
    "                img_resized = cv2.resize(img, (img_width, img_height))\n",
    "                images.append(img_resized)\n",
    "                labels.append(label)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e62d587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images for label: 0\n",
      "Loading images for label: 1\n",
      "Loading images for label: 2\n",
      "Loading images for label: 3\n",
      "Loading images for label: 4\n",
      "Loading images for label: 5\n",
      "Loading images for label: 6\n",
      "Loading images for label: 7\n",
      "Loading images for label: 8\n",
      "Loading images for label: 9\n",
      "Loading images for label: 10\n",
      "Loading images for label: 11\n",
      "Loading images for label: 12\n",
      "Loading images for label: 13\n",
      "Loading images for label: 14\n",
      "Loading images for label: 15\n",
      "Loading images for label: 16\n",
      "Loading images for label: 17\n",
      "Loading images for label: 18\n",
      "Loading images for label: 19\n",
      "Loading images for label: 20\n",
      "Loading images for label: 21\n",
      "Loading images for label: 22\n",
      "Loading images for label: 23\n",
      "Loading images for label: 24\n",
      "Loading images for label: 25\n",
      "Loading images for label: 26\n",
      "Loading images for label: 27\n",
      "Loading images for label: 28\n",
      "Loading images for label: 29\n",
      "Loading images for label: 30\n",
      "Loading images for label: 31\n",
      "Loading images for label: 32\n",
      "Loading images for label: 33\n",
      "Loading images for label: 34\n",
      "Loading images for label: 35\n",
      "Loading images for label: 36\n",
      "Loading images for label: 37\n",
      "Loading images for label: 38\n",
      "Loading images for label: 39\n",
      "Loading images for label: 40\n",
      "Loading images for label: 41\n",
      "Loading images for label: 42\n",
      "Loaded 26640 images.\n",
      "Sample shape: (32, 32, 3)\n",
      "Sample label: 0\n"
     ]
    }
   ],
   "source": [
    "images, labels = load_data()\n",
    "\n",
    "print(f\"Loaded {len(images)} images.\")\n",
    "print(f\"Sample shape: {images[0].shape}\")\n",
    "print(f\"Sample label: {labels[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35f80304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Fast\\sem6\\Ai Lab\\Lab Final\\Dataset_FinalExam\\Dataset_FinalExam\\tf-env\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.1374 - loss: 3.2344 - val_accuracy: 0.5617 - val_loss: 1.4751\n",
      "Epoch 2/15\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5368 - loss: 1.4358 - val_accuracy: 0.8735 - val_loss: 0.4964\n",
      "Epoch 3/15\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7673 - loss: 0.7184 - val_accuracy: 0.9450 - val_loss: 0.2242\n",
      "Epoch 4/15\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8620 - loss: 0.4237 - val_accuracy: 0.9681 - val_loss: 0.1348\n",
      "Epoch 5/15\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9052 - loss: 0.2962 - val_accuracy: 0.9799 - val_loss: 0.0935\n",
      "Epoch 6/15\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9305 - loss: 0.2256 - val_accuracy: 0.9886 - val_loss: 0.0635\n",
      "Epoch 7/15\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9402 - loss: 0.1833 - val_accuracy: 0.9872 - val_loss: 0.0528\n",
      "Epoch 8/15\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9540 - loss: 0.1487 - val_accuracy: 0.9887 - val_loss: 0.0525\n",
      "Epoch 9/15\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9569 - loss: 0.1342 - val_accuracy: 0.9887 - val_loss: 0.0437\n",
      "Epoch 10/15\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9586 - loss: 0.1350 - val_accuracy: 0.9912 - val_loss: 0.0357\n",
      "Epoch 11/15\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9656 - loss: 0.1117 - val_accuracy: 0.9946 - val_loss: 0.0290\n",
      "Epoch 12/15\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9692 - loss: 0.0936 - val_accuracy: 0.9953 - val_loss: 0.0273\n",
      "Epoch 13/15\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9737 - loss: 0.0934 - val_accuracy: 0.9949 - val_loss: 0.0235\n",
      "Epoch 14/15\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9728 - loss: 0.0847 - val_accuracy: 0.9944 - val_loss: 0.0230\n",
      "Epoch 15/15\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9742 - loss: 0.0786 - val_accuracy: 0.9938 - val_loss: 0.0265\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming `images` and `labels` are already loaded and contain all data\n",
    "IMG_WIDTH = 32\n",
    "IMG_HEIGHT = 32\n",
    "NUM_CLASSES = 43\n",
    "\n",
    "# Convert list of images to numpy array\n",
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "X = X / 255.0\n",
    "\n",
    "# One-hot encode labels\n",
    "y = to_categorical(y, NUM_CLASSES)\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Dense(NUM_CLASSES, activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=15, batch_size=64,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbe23d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m167/167\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0306\n",
      "Validation accuracy: 0.9938\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a21ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_single_image(model, image_path, img_width=32, img_height=32):\n",
    "    \"\"\"\n",
    "    Predict the class of a single image\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Keras model\n",
    "        image_path: Path to the image file\n",
    "        img_width: Width to resize image to\n",
    "        img_height: Height to resize image to\n",
    "    \n",
    "    Returns:\n",
    "        predicted_class: The predicted class (0-42)\n",
    "        confidence: Confidence score of the prediction\n",
    "    \"\"\"\n",
    "    # Load and preprocess the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not load image from {image_path}\")\n",
    "    \n",
    "    # Resize image to match training dimensions\n",
    "    img_resized = cv2.resize(img, (img_width, img_height))\n",
    "    \n",
    "    # Normalize pixel values to [0, 1]\n",
    "    img_normalized = img_resized / 255.0\n",
    "    \n",
    "    # Add batch dimension (model expects 4D input)\n",
    "    img_batch = np.expand_dims(img_normalized, axis=0)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_batch, verbose=0)\n",
    "\n",
    "    # Prepare prediction results as a table\n",
    "    results_df = pd.DataFrame({\n",
    "        'Class': list(range(predictions.shape[1])),\n",
    "        'Confidence': predictions[0]*100\n",
    "    })\n",
    "\n",
    "    # Sort by confidence descending\n",
    "    results_df = results_df.sort_values(by='Confidence', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    print(results_df.head(10))  # Show top 10 predictions\n",
    "\n",
    "    \n",
    "    # Get the predicted class and confidence\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    confidence = np.max(predictions[0])\n",
    "    \n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b0c6eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting single image...\n",
      "   Class  Confidence\n",
      "0      0   97.234001\n",
      "1      1    2.321922\n",
      "2      8    0.258520\n",
      "3      4    0.133995\n",
      "4      2    0.049881\n",
      "5      7    0.000932\n",
      "6      5    0.000355\n",
      "7     40    0.000124\n",
      "8     15    0.000062\n",
      "9     24    0.000048\n",
      "\n",
      "\n",
      "\n",
      "Predicted class: 0, Confidence: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting single image...\")\n",
    "cl,conf = (predict_single_image(model, \"Dataset_FinalExam\\\\Q2_dataset\\\\0\\\\00000_00000.ppm\"))  # change this accoridng your needs\n",
    "\n",
    "print(f\"\\n\\n\\nPredicted class: {cl}, Confidence: {conf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7efbf5b",
   "metadata": {},
   "source": [
    "Revenge is a Fool's Game (c) Arthur Morgan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 TF",
   "language": "python",
   "name": "python310tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
